# VHF-LLM Training Guide ğŸ¥

Komplettes Setup fÃ¼r das Training eines LLMs mit dem VHF-Ãœberwachungssystem Datensatz.

## ğŸ“‹ Inhaltsverzeichnis

- [Ãœbersicht](#Ã¼bersicht)
- [Installation](#installation)
- [Verwendung](#verwendung)
- [Scripts](#scripts)
- [Konfiguration](#konfiguration)
- [Troubleshooting](#troubleshooting)

## ğŸ¯ Ãœbersicht

Dieses Repository enthÃ¤lt Scripts zum Training eines Large Language Models (LLM) fÃ¼r ein VHF-Ãœberwachungssystem. Der Datensatz umfasst 300+ EintrÃ¤ge mit medizinischen Dialogen und Anweisungen.

**VerfÃ¼gbare AnsÃ¤tze:**
- **Einfach**: GPT-2 basiertes Training fÃ¼r schnelle Experimente
- **Erweitert**: LoRA-basiertes Fine-tuning fÃ¼r effiziente Anpassung grÃ¶ÃŸerer Modelle

## ğŸš€ Installation

### Automatisches Setup

#### ğŸ§ Linux / ğŸ macOS
```bash
# Repository clonen oder Dateien herunterladen
git clone <repository-url>
cd vhf-llm-training

# Setup Script ausfÃ¼hren
chmod +x setup.sh
./setup.sh
```

#### ğŸªŸ Windows

**Option 1: Command Prompt (CMD)**
```cmd
# Repository clonen oder Dateien herunterladen
git clone <repository-url>
cd vhf-llm-training

# Setup ausfÃ¼hren
setup.bat
```

**Option 2: PowerShell**
```powershell
# Repository clonen oder Dateien herunterladen
git clone <repository-url>
cd vhf-llm-training

# PowerShell Execution Policy setzen (falls nÃ¶tig)
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# Setup ausfÃ¼hren
.\setup.ps1
```

**Option 3: Windows Subsystem for Linux (WSL)**
```bash
# Wie Linux verwenden
chmod +x setup.sh
./setup.sh
```

### Manuelle Installation

#### ğŸ§ Linux / ğŸ macOS
```bash
# Virtual Environment erstellen
python3 -m venv vhf_training_env
source vhf_training_env/bin/activate

# Requirements installieren
pip install -r requirements.txt
```

#### ğŸªŸ Windows
```cmd
# Virtual Environment erstellen
python -m venv vhf_training_env

# Environment aktivieren (CMD)
vhf_training_env\Scripts\activate.bat

# ODER Environment aktivieren (PowerShell)
vhf_training_env\Scripts\Activate.ps1

# Requirements installieren
pip install -r requirements.txt
```

### GPU Setup (optional)

#### CUDA (NVIDIA GPUs)
```bash
# CUDA Version prÃ¼fen
nvidia-smi

# PyTorch mit CUDA Support (alle Plattformen)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### ğŸ macOS (Apple Silicon)
```bash
# Metal Performance Shaders (MPS) Support
pip install torch torchvision torchaudio

# PrÃ¼fen ob MPS verfÃ¼gbar
python -c "import torch; print('MPS verfÃ¼gbar:', torch.backends.mps.is_available())"
```

## ğŸ“Š Datensatz

Platzieren Sie Ihre `Vollstaendiger_Datensatz.json` im Hauptverzeichnis. Der Datensatz sollte folgende Struktur haben:

```json
[
  {
    "id": "A_001",
    "instruction": "Beschreibung der Aufgabe",
    "input": "Eingabe des Patienten",
    "output": "Erwartete Systemantwort",
    "metadata": {
      "module": "A",
      "step": "system_init",
      "...": "..."
    }
  }
]
```

## ğŸ› ï¸ Verwendung

### Virtual Environment aktivieren

#### ğŸ§ Linux / ğŸ macOS
```bash
source vhf_training_env/bin/activate
```

#### ğŸªŸ Windows (CMD)
```cmd
vhf_training_env\Scripts\activate.bat
```

#### ğŸªŸ Windows (PowerShell)
```powershell
vhf_training_env\Scripts\Activate.ps1
```

### Einfaches Training (GPT-2)

#### ğŸ§ Linux / ğŸ macOS
```bash
# Environment aktivieren
source vhf_training_env/bin/activate

# Training starten
python vhf_training_simple.py
```

#### ğŸªŸ Windows
```cmd
# Environment aktivieren
vhf_training_env\Scripts\activate.bat

# Training starten
python vhf_training_simple.py
```

**Vorteile:**
- Schnell und einfach
- Geringer Memory-Verbrauch
- CPU-kompatibel

### Erweiteres Training (LoRA)

#### Alle Plattformen
```bash
# Standard LoRA Training
python vhf_training_advanced.py --use_lora

# Mit Wandb Logging
python vhf_training_advanced.py --use_lora --use_wandb

# GrÃ¶ÃŸeres Modell
python vhf_training_advanced.py --model_name microsoft/DialoGPT-large --epochs 5
```

**Vorteile:**
- Effiziente Anpassung grÃ¶ÃŸerer Modelle
- Weniger GPU Memory benÃ¶tigt
- Bessere Performance

### Parameter-Ãœbersicht

| Parameter | Beschreibung | Standard | Einfach | Erweitert |
|-----------|--------------|----------|---------|-----------|
| `--data_path` | Pfad zum JSON Datensatz | `Vollstaendiger_Datensatz.json` | âœ… | âœ… |
| `--model_name` | Basis-Modell | `gpt2` / `microsoft/DialoGPT-medium` | âœ… | âœ… |
| `--output_dir` | Output Verzeichnis | `./vhf-model-*` | âœ… | âœ… |
| `--epochs` | Anzahl Trainingsepochen | `3` | âœ… | âœ… |
| `--batch_size` | Batch GrÃ¶ÃŸe | `4` | âœ… | âœ… |
| `--learning_rate` | Lernrate | `5e-5` / `2e-4` | âœ… | âœ… |
| `--max_length` | Max Token LÃ¤nge | `512` | âœ… | âœ… |
| `--use_lora` | LoRA verwenden | `False` / `True` | âŒ | âœ… |
| `--use_wandb` | Wandb Logging | `False` | âŒ | âœ… |

## ğŸ§ª Model Testing

### Virtual Environment aktivieren (falls nicht aktiv)

#### ğŸ§ Linux / ğŸ macOS
```bash
source vhf_training_env/bin/activate
```

#### ğŸªŸ Windows (CMD)
```cmd
vhf_training_env\Scripts\activate.bat
```

#### ğŸªŸ Windows (PowerShell)
```powershell
vhf_training_env\Scripts\Activate.ps1
```

### Interaktiver Chat

#### Alle Plattformen
```bash
# Einfaches Modell testen
python vhf_inference.py --model_path ./vhf-model-gpt2 --interactive

# LoRA Modell testen
python vhf_inference.py --model_path ./vhf-model-lora --use_lora --interactive
```

### Batch Testing

#### Alle Plattformen
```bash
# Test Cases erstellen
python vhf_inference.py --create_test_cases

# Batch Test durchfÃ¼hren
python vhf_inference.py --model_path ./vhf-model-lora --use_lora --batch_test test_cases.json
```

### Beispiel-Chat

```
ğŸ“‹ Instruction: Patient meldet sich mit Symptomen, die auf Vorhofflimmern hindeuten kÃ¶nnten
ğŸ“ Input (optional): Ich habe Herzstolpern und fÃ¼hle mich unwohl

ğŸ¤– Generiere Antwort...

ğŸ’¬ Antwort:
Ich verstehe, dass Sie Symptome verspÃ¼ren. Um Ihre Beschwerden zu bewerten, fÃ¼hren wir zunÃ¤chst eine EKG-Aufzeichnung durch. Dies hilft uns dabei festzustellen, ob Vorhofflimmern vorliegt. Sind Sie bereit, jetzt ein EKG durchzufÃ¼hren?
```

## âš™ï¸ Konfiguration

### Standard-Konfigurationen

**CPU Training (wenig RAM) - Alle Plattformen:**
```bash
python vhf_training_simple.py --batch_size 1 --max_length 256
```

**GPU Training (optimiert) - Linux/Windows CUDA:**
```bash
python vhf_training_advanced.py --use_lora --batch_size 8 --max_length 512
```

**ğŸ macOS (Apple Silicon MPS):**
```bash
# Automatische Erkennung von MPS
python vhf_training_advanced.py --use_lora --batch_size 4 --max_length 512
```

**Lange Training Session:**
```bash
python vhf_training_advanced.py --use_lora --epochs 10 --learning_rate 1e-4
```

### Plattform-spezifische Optimierungen

#### ğŸ§ Linux (CUDA)
- Beste GPU-Performance
- UnterstÃ¼tzt alle CUDA-Features
- Empfohlen fÃ¼r intensive Training-Sessions

```bash
# Optimiert fÃ¼r Linux + CUDA
python vhf_training_advanced.py --use_lora --batch_size 8 --gradient_accumulation_steps 1
```

#### ğŸ macOS (Metal Performance Shaders)
- Nutzt Apple Silicon GPU via MPS
- Automatische Erkennung in PyTorch 2.0+
- Begrenzt auf kleinere Batch-Sizes

```bash
# Optimiert fÃ¼r Apple Silicon
python vhf_training_advanced.py --use_lora --batch_size 4 --max_length 384
```

#### ğŸªŸ Windows (CUDA/CPU)
- CUDA support mit NVIDIA GPUs
- Fallback auf CPU bei Problemen
- PowerShell vs CMD beachten

```cmd
# Windows optimiert
python vhf_training_advanced.py --use_lora --batch_size 6 --max_length 512
```

### Modell-Empfehlungen

| Anwendungsfall | Modell | Vorteile |
|----------------|--------|----------|
| Schnelle Experimente | `gpt2` | Klein, schnell, CPU-kompatibel |
| Ausgewogene Performance | `microsoft/DialoGPT-medium` | Gute Balance zwischen GrÃ¶ÃŸe und QualitÃ¤t |
| Beste QualitÃ¤t | `microsoft/DialoGPT-large` | HÃ¶chste QualitÃ¤t, benÃ¶tigt mehr GPU Memory |
| Deutsche Texte | `dbmdz/german-gpt2` | Deutsch-spezifisch |

## ğŸ“ˆ Monitoring & Logging

### Wandb Integration

```bash
# Wandb Account erstellen und Login
pip install wandb
wandb login

# Training mit Logging
python vhf_training_advanced.py --use_lora --use_wandb
```

### Metriken

Das Training protokolliert:
- **Training Loss**: Wie gut das Modell lernt
- **Evaluation Loss**: Wie gut das Modell auf ungesehenen Daten abschneidet
- **Learning Rate**: Aktuelle Lernrate
- **GPU Memory**: Speicherverbrauch

## ğŸ”§ Troubleshooting

## ğŸ”§ Troubleshooting

### HÃ¤ufige Probleme

**1. CUDA Out of Memory**
```bash
# LÃ¶sung: Kleinere Batch Size
python vhf_training_advanced.py --batch_size 2 --gradient_accumulation_steps 2
```

**2. Slow Training**
```bash
# LÃ¶sung: Kleinere Sequence Length
python vhf_training_simple.py --max_length 256
```

**3. Import Errors**
```bash
# LÃ¶sung: Requirements neu installieren
pip install -r requirements.txt --force-reinstall
```

**4. Model Not Loading**
```bash
# Linux/macOS: PrÃ¼fe ob alle Dateien vorhanden sind
ls -la ./vhf-model-*/

# Windows (CMD): PrÃ¼fe Dateien
dir vhf-model-*

# Windows (PowerShell): PrÃ¼fe Dateien
Get-ChildItem -Path "vhf-model-*" -Recurse
```

### Plattform-spezifische Probleme

#### ğŸ§ Linux
**CUDA Driver Issues:**
```bash
# CUDA Installation prÃ¼fen
nvidia-smi
nvcc --version

# PyTorch CUDA Version prÃ¼fen
python -c "import torch; print(torch.version.cuda)"
```

**Permission Errors:**
```bash
# AusfÃ¼hrungsrechte setzen
chmod +x setup.sh

# Virtual Environment Rechte
sudo chown -R $USER:$USER vhf_training_env/
```

#### ğŸ macOS
**Apple Silicon (M1/M2) Probleme:**
```bash
# MPS Support prÃ¼fen
python -c "import torch; print('MPS available:', torch.backends.mps.is_available())"

# Rosetta fallback (wenn nÃ¶tig)
arch -x86_64 python vhf_training_simple.py
```

**Homebrew Python Conflicts:**
```bash
# Python Version explizit verwenden
/opt/homebrew/bin/python3 -m venv vhf_training_env

# Oder pyenv verwenden
brew install pyenv
pyenv install 3.10.11
pyenv local 3.10.11
```

**Xcode Command Line Tools:**
```bash
# Falls Kompilierungsfehler auftreten
xcode-select --install
```

#### ğŸªŸ Windows
**PowerShell Execution Policy:**
```powershell
# Policy prÃ¼fen
Get-ExecutionPolicy

# Policy Ã¤ndern (als Administrator)
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope LocalMachine

# Oder nur fÃ¼r aktuellen User
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

**Python nicht gefunden:**
```cmd
# Python zu PATH hinzufÃ¼gen oder vollstÃ¤ndigen Pfad verwenden
C:\Users\%USERNAME%\AppData\Local\Programs\Python\Python311\python.exe -m venv vhf_training_env
```

**Virtual Environment Aktivierung Probleme:**
```cmd
# Falls activate.bat nicht funktioniert
vhf_training_env\Scripts\python.exe -m pip install -r requirements.txt

# PowerShell alternative
& "vhf_training_env\Scripts\python.exe" -m pip install -r requirements.txt
```

**CUDA Installation Windows:**
```cmd
# NVIDIA Driver prÃ¼fen
nvidia-smi

# CUDA Toolkit Installation prÃ¼fen
nvcc --version

# PyTorch CUDA Windows
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Long Path Support:**
```cmd
# Git clone mit long paths (als Administrator)
git config --system core.longpaths true

# Oder Windows Registry Ã¤ndern (nicht empfohlen)
```

### Environment Debugging

#### Alle Plattformen
```bash
# Python Environment Info
python -c "import sys; print('Python:', sys.version)"
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "import transformers; print('Transformers:', transformers.__version__)"

# GPU Info
python -c "import torch; print('CUDA available:', torch.cuda.is_available()); print('Device count:', torch.cuda.device_count() if torch.cuda.is_available() else 0)"

# Memory Info
python -c "import psutil; print(f'RAM: {psutil.virtual_memory().total // (1024**3)} GB')"
```

#### Modell-Loading Debug
```bash
# Schritt-fÃ¼r-Schritt Debugging
python -c "
import os
model_path = './vhf-model-lora'
print('Model dir exists:', os.path.exists(model_path))
print('Files in model dir:')
if os.path.exists(model_path):
    for f in os.listdir(model_path):
        print(f'  {f}')
"
```

### System Requirements

#### Minimum (alle Plattformen):
- Python 3.8+
- 8GB RAM
- 10GB freier Speicherplatz

#### Empfohlen:

**ğŸ§ Linux:**
- Ubuntu 20.04+ / CentOS 8+
- Python 3.10+
- 16GB+ RAM
- NVIDIA GPU mit 8GB+ VRAM (CUDA 11.8+)
- 50GB freier Speicherplatz

**ğŸ macOS:**
- macOS 12.0+ (Monterey)
- Apple Silicon (M1/M2) oder Intel
- Python 3.10+ (Homebrew empfohlen)
- 16GB+ unified Memory
- 50GB freier Speicherplatz

**ğŸªŸ Windows:**
- Windows 10/11 (64-bit)
- Python 3.10+ (Microsoft Store oder python.org)
- 16GB+ RAM
- NVIDIA GPU mit 8GB+ VRAM (CUDA 11.8+)
- 50GB freier Speicherplatz
- PowerShell 5.1+ oder Windows Terminal

### Performance-Tipps

#### Plattform-Ã¼bergreifend:
1. **FÃ¼r CPU Training**: Verwenden Sie kleine Modelle (`gpt2`) und kleine Batch Sizes
2. **FÃ¼r GPU Training**: Nutzen Sie LoRA fÃ¼r effizienten Memory-Verbrauch
3. **FÃ¼r lange Sessions**: Aktivieren Sie Checkpointing mit `--save_steps 100`

#### ğŸ§ Linux-spezifisch:
- Nutzen Sie `htop` fÃ¼r Memory-Monitoring
- Setzen Sie `ulimit -n 65536` fÃ¼r mehr File Handles
- Verwenden Sie `screen` oder `tmux` fÃ¼r lange Training Sessions

#### ğŸ macOS-spezifisch:
- Ãœberwachen Sie Memory mit Activity Monitor
- Nutzen Sie MPS fÃ¼r GPU-Beschleunigung auf Apple Silicon
- Beachten Sie thermal throttling bei lÃ¤ngeren Sessions

#### ğŸªŸ Windows-spezifisch:
- Verwenden Sie Task Manager fÃ¼r Performance-Monitoring
- Aktivieren Sie Developer Mode fÃ¼r bessere Performance
- Nutzen Sie Windows Terminal fÃ¼r bessere KompatibilitÃ¤t

## ğŸ“ Datei-Ãœbersicht

```
vhf-llm-training/
â”œâ”€â”€ ğŸ“„ vhf_training_simple.py      # Einfaches GPT-2 Training
â”œâ”€â”€ ğŸ“„ vhf_training_advanced.py    # Erweiteres LoRA Training
â”œâ”€â”€ ğŸ“„ vhf_inference.py           # Model Testing & Chat
â”œâ”€â”€ ğŸ“„ requirements.txt           # Python Dependencies
â”œâ”€â”€ ğŸ§ setup.sh                  # Setup Script (Linux/macOS)
â”œâ”€â”€ ğŸªŸ setup.bat                 # Setup Script (Windows CMD)
â”œâ”€â”€ ğŸªŸ setup.ps1                 # Setup Script (Windows PowerShell)
â”œâ”€â”€ âš™ï¸ config.json              # Beispiel-Konfiguration
â”œâ”€â”€ ğŸ“Š Vollstaendiger_Datensatz.json  # Ihr VHF Datensatz
â”œâ”€â”€ ğŸ“š README.md                # Diese Anleitung
â””â”€â”€ ğŸ“ vhf_training_env/         # Virtual Environment (nach Setup)
    â”œâ”€â”€ ğŸ§ bin/activate          # Linux/macOS Aktivierung
    â””â”€â”€ ğŸªŸ Scripts/
        â”œâ”€â”€ activate.bat         # Windows CMD Aktivierung
        â””â”€â”€ Activate.ps1         # Windows PowerShell Aktivierung
```

## ğŸ’» Plattform-spezifische Quickstarts

### ğŸ§ Linux Quickstart
```bash
git clone <repository-url>
cd vhf-llm-training
chmod +x setup.sh && ./setup.sh
source vhf_training_env/bin/activate
python vhf_training_simple.py
```

### ğŸ macOS Quickstart
```bash
# Homebrew Python installieren (falls nÃ¶tig)
brew install python3

git clone <repository-url>
cd vhf-llm-training
chmod +x setup.sh && ./setup.sh
source vhf_training_env/bin/activate
python vhf_training_simple.py
```

### ğŸªŸ Windows Quickstart (CMD)
```cmd
git clone <repository-url>
cd vhf-llm-training
setup.bat
vhf_training_env\Scripts\activate.bat
python vhf_training_simple.py
```

### ğŸªŸ Windows Quickstart (PowerShell)
```powershell
git clone <repository-url>
cd vhf-llm-training
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
.\setup.ps1
vhf_training_env\Scripts\Activate.ps1
python vhf_training_simple.py
```

## ğŸ¤ Support

Bei Problemen:

1. PrÃ¼fen Sie die [Troubleshooting](#troubleshooting) Sektion
2. Stellen Sie sicher, dass alle Requirements installiert sind
3. Testen Sie zunÃ¤chst mit kleinen Konfigurationen
4. Ã–ffnen Sie ein Issue mit detaillierter Fehlerbeschreibung

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT Lizenz - siehe die [LICENSE](LICENSE) Datei fÃ¼r Details.

---

**Viel Erfolg beim Training Ihres VHF-LLMs! ğŸ¥ğŸ¤–**